---
title: "Fairness/causation: Stop and Frisk dataset"
output: github_document
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(forcats)
library(ggplot2)
library(reshape2)
source("functions.R")
options(dplyr.width = Inf)
```

## Data

From the [NYC Stop and Frisk dataset](http://www.nyclu.org/content/stop-and-frisk-data) @stop:2014. 

```{r}
source("load_stopandfrisk.R")
data <- stopandfrisk
data$found <- apply(data[,c("pistol", "knifcuti", "contrabn", "othrweapon")], 1, function(x) any(x == 1))
data$charged <- apply(data[,c("arstmade", "sumissue")], 1, function(x) any(x == 1))
data$force <- apply(data[,pf_cols], 1, function(x) any(x == 1))

meancharged <- mean(data$charged)
data$charged <- data$charged - meancharged
output <- data[,c("race", "sex", "charged")]
res <- "charged"
prot <- c("race", "sex")
t(head(data))[,1:3]
#print(reasoncols)
```

## Imbalances in the data

Average outcomes by race.

```{r}
data %>% filter(charged == 1) %>% group_by(race) %>% summarise(count = n(), force = mean(force))
```

### Linear regression

Predicted averages coincide with data averages.

```{r}
model.lm <- lm(arstmade ~ .-1, data)
output$predlm <- predict(model.lm)
```

### Blinded to unfair covariates

Outcomes are only slightly less biased.

```{r}
lm.blind <- fairpred_blind(data, res, prot, method = "lm")
output$lmblind <- predict(lm.blind)
```

### Two-stage procedure

Greedily enforces fairness first, then builds predictions.

```{r}
lm.lm <- fairpred_2s(data, res, prot, method1 = "lm", method2 = "lm")
output$lm_lm <- predict(lm.lm)
```

### Penalizing unprotected coefficients

```{r}
ridge <- fairpred_pen(data, res, prot, alpha = 0)
output$ridge <- ridge$predictions

enet <- fairpred_pen(data, res, prot, alpha = .5)
output$enet <- enet$predictions
```

### Comparing imbalance

Subgroup means.

```{r}
output <- output %>% mutate_if(is.numeric, funs(. + meanarst))
output %>% group_by(race) %>% summarise_if(is.numeric, .funs = funs("mean"))
```

Distribution plots.

```{r}
pd <- melt(output)
ggplot(pd, aes(value, fill = sex)) + geom_density(alpha = .3) +
  facet_wrap(~variable) + xlim(-.5, 1) + theme_bw()

ggplot(pd, aes(value, fill = race)) + geom_density(alpha = .3) +
  facet_wrap(~variable) + xlim(-.5, 1) + theme_bw()
```

### Comparing (in-sample) mean-squared prediction error

```{r}
outputMSE <- data.frame((output$arstmade - output[,4:ncol(output)])^2)
outputMSE$const <- output$arstmade^2
outputMSE %>% summarise_all("mean")
```
