---
title: "Fairness/causation: Adult dataset"
output: github_document
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(reshape2)
library(e1071)
library(glmnet)
source("functions.R")
options(dplyr.width = Inf)
```

## Data

From the [UCI databases](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names) @Lichman:2013. 

```{r, cache=TRUE}
url <- "http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
adult <- read.csv(url, strip.white = TRUE, header = FALSE)
names(adult) <- c("age", "workclass", "fnlwgt", "education", "educationnum",
                  "maritalstatus", "occupation", "relationship", "race", "sex",
                  "capitalgain", "capitalloss", "hoursperweek",
                  "nativecountry", "income")
adult$fnlwght <- NULL # Survey weights -- for generalization
data <- adult[,c("workclass", "occupation", "education", "educationnum",
                 "nativecountry", "race", "sex", "age")]
data$hours <- adult$hoursperweek - mean(adult$hoursperweek)
res <- "hours"
prot <- c("sex", "race")
output <- data[,c(prot, res)]
t(head(data))[,1:3]
```

## Imbalances in the data

Average outcomes by sex/race.

```{r}
data %>% group_by(sex) %>% summarise(count = n(), hours = mean(hours))
data %>% group_by(race) %>% summarise(count = n(), hours = mean(hours))
```

Distribution plot.

```{r}
ggplot(data, aes(hours, linetype = sex)) + geom_density() + theme_bw()
```

### Linear regression

Predicted averages coincide with data averages.

```{r, cache=TRUE}
model.lm <- lm(hours ~ ., data)
output$lm <- predict(model.lm)

model.svm <- svm(hours ~ ., data)
output$svm <- predict(model.svm)
```

### Blinded to unfair covariates

Outcomes are only slightly less biased.

```{r, cache=TRUE}
lm.blind <- fairpred_blind(data, res, prot, method = "lm")
output$lmblind <- predict(lm.blind)

svm.blind <- fairpred_blind(data, res, prot, method = "svm")
output$svmblind <- predict(svm.blind)
```

### Two-stage procedure

Greedily enforces fairness first, then builds predictions.

```{r, cache=TRUE}
lm.lm <- fairpred_2s(data, res, prot, method1 = "lm", method2 = "lm")
output$lm_lm <- predict(lm.lm)

lm.svm <- fairpred_2s(data, res, prot, method1 = "lm", method2 = "svm")
output$lm_svm <- predict(lm.svm)

svm.svm <- fairpred_2s(data, res, prot, method1 = "svm", method2 = "svm")
output$svm_svm <- predict(svm.svm)
```

### Penalizing unprotected coefficients

```{r, cache=TRUE}
glmn <- fairpred_pen(data, res, prot)
output$glmnet <- predict(glmn$model, newx=glmn$x, s = "lambda.1se")[,1]
```

### Comparing imbalance

Subgroup means.

```{r}
output %>% group_by(sex) %>%
  summarise_if(.predicate = function(v) is.numeric(v), .funs = funs("mean"))

output %>% group_by(race) %>%
  summarise_if(.predicate = function(v) is.numeric(v), .funs = funs("mean"))
```

Distribution plots.

```{r}
pd <- melt(output)
ggplot(pd, aes(value, fill = sex)) + geom_density(alpha = .3) +
  facet_wrap(~variable) + xlim(-15, 15) + theme_bw()

ggplot(pd, aes(value, fill = race)) + geom_density(alpha = .3) +
  facet_wrap(~variable) + xlim(-15, 15) + theme_bw()
```

### Comparing (in-sample) mean-squared prediction error

```{r}
outputMSE <- data.frame((output$hours - output[,4:ncol(output)])^2)
outputMSE$const <- output$hours^2
outputMSE %>% summarise_all("mean")
```
